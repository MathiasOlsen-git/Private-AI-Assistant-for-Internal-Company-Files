from sentence_transformers import SentenceTransformer
import faiss
import pickle

# IndlÃ¦s FAISS index og metadata
index = faiss.read_index("vectorstore/index.faiss")
with open("vectorstore/metadata.pkl", "rb") as f:
    metadata = pickle.load(f)

# IndlÃ¦s den samme model som ved embedding
model = SentenceTransformer("all-MiniLM-L6-v2")

def retrieve_relevant_chunks(question, top_k=3):
    question_embedding = model.encode([question])
    distances, indices = index.search(question_embedding, top_k)

    results = []
    for idx in indices[0]:
        results.append(metadata[idx])
    return results

# Test-funktion
if __name__ == "__main__":
    user_question = input("ğŸ” Stil et spÃ¸rgsmÃ¥l: ")
    top_chunks = retrieve_relevant_chunks(user_question)

    print("\nğŸ“„ Mest relevante tekstbidder:\n")
    for i, chunk in enumerate(top_chunks, 1):
        print(f"{i}. ({chunk['source']})\n{chunk['text']}\n")
